\documentclass[12pt, letterpaper]{article}

\usepackage{amsmath, amsthm, graphicx, float, verbatim, amssymb}
\newcommand\tab[1][1cm]{\hspace*{#1}}

\usepackage[]{algorithm2e}

\title{Natural Language Processing Homework 5}

\author{Katie Chang}

\begin{document}

\maketitle

README

%\section{Simplify (Q2, no need to turn in)}
%Mostly just notes for myself

%check out d) ($\lambda$a a)($\lambda$b f(b))

%f), simplifying ($\lambda$x green(x))(y) = green(y).
%Since the result holds for any y, what can you conclude about the relation between $\lambda x green(x)$ and $green$?

%Same? $\lambda x green(x)$ applied to anything $y$ means that that something $y$ is green. Similarly, $green$ as a function can be applied to anything $z$ that is green. In any case, they refer to the same set of things??

%wait i don't get o)

\section{(Q3) Simplify}

\subsection{John and Mary}
Given $f(John = loves(Mary, John)$

\begin{itemize}  
\item ($\lambda x loves(Mary,x)$)(John)
\item $loves(Mary, John)$ or alternatively, depending on semantics, "Mary loves John" or "John loves Mary".
\end{itemize}

\subsection{part b}
%In our semantics, loves(Mary,John) will be the interpretation of “John loves Mary,” not vice-versa. This is just more convenient because then the VP in that sentence has a nice, compact semantics. Namely, what?

%With the parse tree given for this sentence (as it's in in the semantics slideshow page 52), $\lambda x$ represents "John" and is the NP and $\lambda y$ represents Mary in the VP "loves Mary". If it is flipped, then the parse tree would be different. Furthermore, we'd have to deal with a change in the order we parse. If the meaning is flipped, we'd have to handle $\lambda y$ first, however that is impossible because $\lambda x$ is outside and thus has to be handled first.

$\lambda y$ loves(Mary, y)

\subsection{part c}
%f(John) = (∀x woman(x) ⇒ loves(x,John))

\begin{itemize}  
\item %what is f?
($\lambda j \forall x woman(x) \Rightarrow loves(x,j)$) 
\item %Translate f and f(John) into English.
Assuming that we will continue with the given semantic that loves(Mary, John) means that John loves Mary.

f : for all x, if x is a woman, then j loves x.

f(John) : for all x, if x is a woman, then John loves x.

\end{itemize}

\subsection{part d}

f = $\lambda y$ $\lambda x$ Obviously(y(x))

In order to construct "Sue obviously loves Mary", let y = ($\lambda x loves(Mary, x)$). This maintains the encapsulation of the $\lambda x$ within the Obviously() semantic. 

\subsection{part e}
f = $\lambda m ( \lambda j ( \lambda e$ act(e, loving), lovee(e, m), lover(e, j)))

\subsection{part f}

g = $\lambda f \lambda y \lambda e$ $f(y)(e)$, manner(e, passionate)

\subsection{part g}

i. f = $\lambda x \forall y$ woman(y) $\Rightarrow$ x(y)

ii. 

For all y, if y is a woman then y loves Mary.

x loves Mary.

For all y, if y is a woman then x(y).

\subsection{part h}

i. g = $\lambda f \lambda x \forall y$ f(y) $\Rightarrow$ x(y)

ii. "Every"

\subsection{part i}

i. $\lambda y$ y(Papa)

ii. %funny semantics?

\section{Q4}

''Laura say -s that George might sleep on the floor ! ''
Breaks on Preposition; on the floor is not assigned to sleep, but instead to Laura says. 


''Papa would have eat -ed his sandwich -s . ''
It is ambiguous. Sandwich is assigned to `his'. This is technically okay but I'm including this to demonstrate how the ambiguity of the original sentence affects the attributes/semantics.

''Papa sleep -s every bon bon with a spoon . ''
It breaks at ``sleeps every bon bon''. Sentence is grammatical and parses correctly, but gives the error: '' No consistent way to assign attributes!''


''A bon bon on the spoon entice -0 . '
No consistent way to assign attributes!; 

''Every sandwich was going to have been delicious . ''
I actually have no idea what's wrong here. I just thing this sentence sucks.

''the fine and blue woman and every man must have eat -ed two sandwich -s and sleep -ed on the floor .'''
No consistent way to assign attributes!; This is likely due to our parse as the VP cannot have attributes assigned correctly. 


\section{Q5}
Included in the submission is the file

question5english.gra

which includes the changes to accommodate for mass nouns.

Also included is a small sentence file (question5english.sen) with three sentences that can be built with buildattrs and one that cannot. 

We are able to say that "someone ate the caviar". However, due to semantics, we can't say "someone ate caviar", since mass nouns do have to be able to represent both single and plural nouns in a way. While this sentence works grammatically for plural nouns, it doesn't work for singular nouns. 

This grammar works with the sentence "All caviar is delicious".

\section{Q6 : english-fullquant.gra}
\subsection{attr}

%1 Det[=1 num=pl sem="%dom %pred E%first E%second [first!=second ^ dom(first)^dom(second)] ^ pred(first) ^ pred(second)"] two

For $two$, we are ensuring that the two things that we are quantifying are not the same thing, with the $first$ and $second$ quantifiers on the $dom$ and $pred$ variables. Otherwise, we can end up counting a given something twice, which in reality then doesn't mean that we have two, but rather that we just counted one thing twice. 

%1 Det[=1 num=sing sem="%dom %pred E%t [dom(t) ^ !E%u u!=t ^ dom(u)] ^ pred(t)"] the

The singular $the$ has semantics that ensure that, while there are two objects $t$ and $u$, the object that this 'the' determinant is operating on is $t$ and not on $u$. 

For example, let t = a book, and let u = a book, where t != u. We want to identify a specific book $t$, and no other book. 

%1 Det[=1 num=pl sem="%dom %pred E%T [exhaustive(T,dom)] ^ pred(T)"] the

The plural $the$ has semantics that states that the determinant applies to the exhaustive set of objects of which we want to apply $the$ on. 

Taking the book example again, we are applying $the$ to a whole set of books (within reason, ie. all of the books on a bookshelf). 

\subsection{???}
Edited in english-fullquant.par. %BUT NOT YET

\begin{center}
\textit{Used overleaf.com to generate LaTeX document.}
\end{center}
\end{document}
